[{"content":"üë®‚Äçüíª I\u0026rsquo;m Jonas, a Software Developer with a keen focus on crafting robust Software Architectures in ‚òïÔ∏è Java. I thrive at the crossroads of business and technology, always keeping a pragmatic perspective on both realms. üëâ My approach is rooted in a combination of proven methodologies, including Extreme Programming (XP), Test-Driven Development (TDD), and Domain-Driven Design (DDD). I believe that these principles pave the way for scalable, efficient, and maintainable software solutions.\n","date":null,"permalink":"/","section":"","summary":"üë®‚Äçüíª I\u0026rsquo;m Jonas, a Software Developer with a keen focus on crafting robust Software Architectures in ‚òïÔ∏è Java.","title":""},{"content":"TL;DR of the Test First series.\nAs we conclude the Test First series, I\u0026rsquo;d like to revisit and emphasize the key takeaways from our discussions.\nTest Driven Development (TDD) is a practical tool that, when understood and applied correctly, within the right context, can be highly beneficial. TDD isn\u0026rsquo;t about adhering to a strict dogma, or looking down on those who haven\u0026rsquo;t adopted it;\nTDD is fundamentally about ensuring that your codebase remains robust against regressions during:\nRefactorings Introduction of new features Modifications to existing features Additionally TDD also plays a crucial role in the design of our applications. Once we have a working feature, regardless of its initial quality or elegance, having robust tests in place enables us to modify the internal workings with confidence.\nThis ensures that changes made to improve or optimize the code (after our initial green tests or even months later when refactoring) do not inadvertently introduce errors or regressions.\nDo not confuse a working feature by working code. A feature is implemented by code, but the code itself is not the feature nor the goal of what should be tested.\nTo effectively achieve this, it\u0026rsquo;s crucial to write tests at an appropriate level of abstraction. But what is the right level of abstraction?\nStop wasting time Unit Testing #A Unit Test, as all to often misunderstood as a method or class test, is definitely not the right level of abstraction to form a proper foundation of any test suite. For that reason, the classical testing pyramid has become obsolete.\nThe foundation of your test codebase, if based on testing each layer, class, or method in isolation, tends to be counterproductive. This approach can result in a fragile codebase, one that is prone to failure with the slightest changes, rather than fortifying it against regressions.\nAt the heart of your testing approach should be a focus on behavior, followed by implementation details. Grasping this distinction within your own codebase is a significant aspect of test architecture. Understanding that tests should primarily verify the behavior of the system ‚Äî how it reacts and what it does ‚Äî and then consider the specific ways these behaviors are implemented, is key. This approach ensures that tests remain relevant and valuable, even as the implementation evolves over time.\nArchitecture also for our tests #It\u0026rsquo;s vital to treat our test codebase with the same seriousness as our production code architecture. Planning and understanding the rationale behind the structure of the test suite are essential. This clarity should extend to all project participants, ensuring a cohesive and effective testing strategy.\nTest First #Writing tests before production code encourages thoughtful consideration of the system\u0026rsquo;s requirements and behaviors. It also puts the focus on testing architecture - figuring out how to test the features - enhances the process. In contrast, starting directly with production code can turn these considerations into hurdles.\nA Test-first mindset aims to enable the creation of better, more change-resilient production code, by integrating testing as a fundamental part of the development process, if conducted at the right level of abstraction.\nIn the end, our tests are more important than our production code. Because without tests, we can\u0026rsquo;t be confident to change our production code and in doing so being able to move our software products forward at a steady peace.\n","date":"17 March 2024","permalink":"/posts/test-first-tldr/","section":"Jonas on Software","summary":"\u003cp\u003eTL;DR of the Test First series.\u003c/p\u003e","title":"\u003cspan style=\"color: #606a79; font-size: 90%;\"\u003eTest First Ôºç Part 5\u003c/span\u003e\u003cbr/\u003e TL;DR"},{"content":"","date":null,"permalink":"/tags/java/","section":"Tags","summary":"","title":"Java"},{"content":" ‚õµ Navigating the realm of Java, Software Architecture and Testing with in-depth explorations and practical insights. #","date":null,"permalink":"/posts/","section":"Jonas on Software","summary":"‚õµ Navigating the realm of Java, Software Architecture and Testing with in-depth explorations and practical insights.","title":"Jonas on Software"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/tdd/","section":"Tags","summary":"","title":"TDD"},{"content":"","date":null,"permalink":"/tags/testing/","section":"Tags","summary":"","title":"Testing"},{"content":"Your tests also deserve some architecting\nTL;DR #Partition first by behavior, then by architectural layers\nArchitecture plays a critical role at all levels of the software development process, yet one level often gets overlooked.\nTypically, our architectural efforts are focused on production code, often overlooking a vital component: the test code. To maximize the benefits of your test suite, integrating your test design into your overall architectural decisions is essential.\nYour tests also deserve some architecting #The test suite is often treated with an indifferent attitude, as if its structure and design are of minor importance. Even when somewhat architecturally cared for, it seldom extends beyond dictating a certain percentage of code coverage, which on its own is a poor metric of quality.\nA thoughtfully designed test suite is essential for the sustained success of any application, facilitating continuous and steady advancement of the production code base. It also contributes to a coherent and comprehensible base for future changes. These benefits are frequently underestimated.\nA testing architecture must provide clear guidelines on several essential aspects:\nLevels and Types of Tests: specify which types of tests are conducted at different levels of the application and explain the reasoning behind these choices. Test Data Management: define strategies for setting up and tearing down test environments, which could include using patterns like Test Object Managements using, i.e. Object Mothers Spring Context Management. databases, message-brokers and other infrastructural components data setup and clean-up strategies. Reusable Components and Extensibility: Identify available reusable components, such as standardized fixtures or helper methods. Documenting these and other resources promotes efficiency, reduces redundancy, and fosters uniformity across the testing code base.\nThe right level of partitioning #Software architecture abstracts an application into layers or components, each with a dedicated responsibility What often happens is that these layers are used to partition your tests by a specific type of test.\nThis line of thinking leads to a brittle test code base that breaks down upon every refactoring.\nEven worse is when all layers are tested individually in isolation completed by one big integration test. Ever saw a mapper being tested in isolation? That\u0026rsquo;s a clear sign of this anti-pattern.\nIf not a mapper-test then maybe a test like this looks recognizable?\nclass PersonService { public void createPerson(Person person) { personRepository.save(person); } } // Test Code var personRepository = mock(PersonRepository.class); var personService = new PersonService(personRepository); var person = PersonMother.male(); personService.createPerson(person); verify(personRepository).save(person); At first glance, this test seems reasonable ‚Äì it checks if PersonService calls save on personRepository. However, this test is inherently flawed as it tightly couples the test to a specific implementation detail of PersonService. The issue here is that if the implementation of createPerson changes, even if the overall behavior remains the same, the test may fail.\nThis creates a fragile testing environment, where tests break due to implementation changes rather than actual bugs or behavioral changes.\nStill not convinced? Then you probably misunderstood what is meant by behavior.\nBehavior once more #By behavior, I\u0026rsquo;m referring to the overall functionality of the application as it relates to business rules and user interactions, not the details of code, methods, or classes. This behavior is the practical manifestation of what the application does, making the code itself a secondary, supporting detail.\nTo build more robust tests, it\u0026rsquo;s vital to partition tests based on behavior before partitioning them based on architectural layers. Partitioning based on architectural layers is not wrong perse, but it should not be the primary partitioning strategy.\nBy focusing on what the application is supposed to do, rather than how it does it (its implementation), tests become more resilient to changes in your codebase.\n","date":"10 March 2024","permalink":"/posts/architecture-is-not-only-for-production-code/","section":"Jonas on Software","summary":"\u003cp\u003eYour tests also deserve some architecting\u003c/p\u003e","title":"\u003cspan style=\"color: #606a79; font-size: 90%;\"\u003eTest First Ôºç Part 4\u003c/span\u003e\u003cbr/\u003e Architecture is not only about production code"},{"content":"Looking at an Ancient Structure\nTL;DR #The classical testing pyramid focuses on the cost of writing, running, and maintaining tests, which is a narrow and single-minded perspective not adapted to today\u0026rsquo;s technology landscape.\nIn the second part of this series, I stress the importance of focusing on testing actual requirements, behavior, use-cases, and not implementation details like methods and classes.\nYet things aren\u0026rsquo;t merely as simple as that. Through shedding new light on the classical testing pyramid, this article will challenge long-held testing dogmas, advocating for a paradigm shift that better aligns with the complexities and nuances of contemporary software ecosystems\nA short history lesson #Most developers are familiar with the concept of the testing pyramid, introduced by Mike Cohn in his book \u0026ldquo;Succeeding with Agile: Software Development Using Scrum\u0026rdquo; back in 2009. It suggests an ideal test distribution:\nA solid base of unit tests A middle layer of integration tests A smaller top layer of end-to-end tests The pyramid emphasizes a particular aspect of test type distribution, primarily based on the cost ‚Äî in terms of time and money ‚Äî associated with writing, running, and maintaining tests. However, it solely considers this aspect of cost distribution, overlooking other valuable factors that should also be taken into account. Unit Tests are a Weak Foundation #In today\u0026rsquo;s software development world, the testing pyramid\u0026rsquo;s foundation isn\u0026rsquo;t as sturdy as it once was. It\u0026rsquo;s built on the idea that having many unit tests equals a well-tested application, but this can be highly misleading. As we discussed before, the ambiguous nature of unit testing in our industry typically guides us to write numerous isolated tests, all while mocking out external dependencies. This practice eventually leads to a brittle test codebase.The focus on technical distribution steers us away from the real goal of testing behavior.\nIn essence, the classical testing pyramid tells us how to test things, but it\u0026rsquo;s not all that relevant because it doesn\u0026rsquo;t help us:\nprevent regression document our software refactor freely and evolve our applications at a steady pace, all of that when making changes without altering requirements Honeycomb to the rescue #With the exponential growth of the web came the need for microservices, the evolution of architectural patterns, new types of databases, queues, and the ever-increasing speed and power of our computers. We are no longer creating the same applications as we did in the past. I argue that these shifts have undoubtedly influenced the way we write tests.\nOver the past decade, there has been a noticeable shift towards a multitude of leaner services, moving away from monolithic applications. These modern services are often simplified, with a reduced business responsibility, while the emphasis has shifted towards integration with other services and infrastructural components.\nAdvancements in CPU cycles and virtualization have propelled us into an era where entire databases can be spun up in a matter of seconds when running tests, thanks to tools like Testcontainers.\nAs a response to these changes, the testing honeycomb model has emerged, placing greater emphasis on integration tests and placing less focus on implementation details and integrated tests.\nA Honeycomb++ #From today\u0026rsquo;s perspective, I recognize increased value in the testing honeycomb, positioning integration tests as the cornerstone of a modern testing approach. I would like to propose a minor adjustment, shifting focus from the type of test to the true value of testing ‚Äì in other words, emphasizing the importance of testing behavior. Spotlight On Behavior Testing #At its core, you test the behavior of your system through various means such as unit, integration, slice, component, or any other type of test required.\nüëâ A behavior test says nothing about the type of test, being unit or integration. This choice, or rather architectural decision, is yours to take and varies for each context.\nImplementation detail #It is important to state that testing implementation details, even on a class or method level, is not wrong and at times even necessary, especially for complex logic within a component.\nüëâ However, it should never, like the classical testing pyramid implicitly proposes, be the foundation of your test distribution.\nTo admit, it\u0026rsquo;s not always clear what actually is an implementation detail test. This is something that should be formulated for every project and is part of the architecture of your application.\nTesting implementation details means focusing on the specific, internal workings of a piece of software, such as the methods, classes, and internal state and flow, rather than on its overall behavior or the outcomes it produces.\nInternal Focus: These tests concentrate on the internal structure of the code, rather than on what the code does from a behavioral perspective.\nSusceptibility to Change: Tests that focus on implementation details are often fragile and prone to failure with code refactoring or internal changes, even when the external behavior remains consistent.\nState Verification: They frequently involve verifying the internal state of an object or the interactions between internal components, rather than the end result or output of a process.\nIt is easy to fall into the trap of over-testing simple orchestration code. This occurs when tests are written for code that merely coordinates or orchestrates calls to other components. For instance, testing an isolated Spring MVC controller or service might seem beneficial, but if these tests only assess how the code is structured internally, rather than how it behaves or interacts with other layers within the system, they may be focusing too much on implementation details.\nIntegrated #These tests are conducted in actual environments to identify integration failures, and that can even be in production. Often, our system landscape includes a variety of microservices, databases, queues, and other infrastructure components. These are orchestrated by a complex mix of release and deployment pipelines, comprising scripts, infrastructure-as-code definitions, and configuration files. Collectively, they form a functioning end-to-end system.\nAn integrated test examines the entire landscape in an actual environment, akin to a smoke test.\nTo offer a more concrete example: in a recent project, I worked with Kafka, where AVRO messages were published. This process required a pre-existing schema in a component known as the schema-registry. Frequently, someone would forget to add or update the schema in our Terraform repository.\nAll tests locally were succeeding, and even upon deployment to the dev environment, everything seemed up and running. Until our automated test fired some calls against the system that caused it to fail because of the missing schema. This could indeed have been captured by a manual test, yet there is great value in automating things.\nWhat does an integrated test it look like? #It can be as simple as a set of shell or python scripts firing off some requests against the system and waiting for a certain response. Something that can be run after each deployment in an environment.\nMapping the cost and duration on the Honeycomb #When we map the cost and duration of tests onto the honeycomb model, a more balanced distribution emerges. With the behavior tests being the most balanced as they can be both slow and fast at the same time. There is a cost to implementation detail tests, as they are susceptible to break upon refactoring. Integrated tests, on the other hand, represent the highest expense in both execution and maintenance, due to their complex nature and the ongoing challenge of upkeep.\nüëâ In essence, when all behavior is thoroughly tested, it often results in most of the code being effectively covered.\n","date":"5 February 2024","permalink":"/posts/relevance-of-the-classical-testing-pyramid/","section":"Jonas on Software","summary":"\u003cp\u003eLooking at an Ancient Structure\u003c/p\u003e","title":"\u003cspan style=\"color: #606a79; font-size: 90%;\"\u003eTest First Ôºç Part 3\u003c/span\u003e\u003cbr/\u003e On the Relevance of the Classical Testing Pyramid"},{"content":"On the Misconceptions Surrounding the Unit in Unit Testing\nTL;DR #The unit you want to test is not a class nor a method but a behavior.\nIn the first part of this series, I stress the importance of prioritizing a well-designed and overall reliable test suite over strict adherence to the TDD mantra. However, defining what constitutes a well-designed and reliable test suite raises the question of what should be tested, or more precisely, what the unit under test is.\nIf you were to ask a group of developers to give a definition of a Unit Test, you\u0026rsquo;d likely receive a plethora of different responses. Likewise, within the industry, there is a lot of ambiguity around what a Unit Test exactly is. We simply cannot agree on a common concept what the unit exactly represents.\nIn the second part of this testing series, I aim to clarify this ambiguity by defining what actually should be tested or what the unit actually is. This will pave the way for a deeper understanding of the true value of writing tests.\nNot The Smallest Testable Module #Unfortunately, the term \u0026ldquo;Unit Testing\u0026rdquo; has become synonymous with testing overall. Conversely, a common definition of Unit Testing is the smallest testable component that can be isolated1. For many, this translates to testing a single public method or class, leading to the pitfalls of brittle test suites and misconceptions about testing and difficulties with TDD.\nUnit Tests: A Source of Brittleness #Test code bases composed of numerous small tests focused on methods and classes often suffer from brittleness. A brittle test suite breaks with even the slightest code alterations unrelated to changing requirements. This becomes particularly evident when routine code refactors, such as adding a dependency or a parameter, result in test failures.\nIf your test code base fractures in response to minor alterations without changes in requirements, it\u0026rsquo;s a clear indication of a poorly designed test suite. Awareness of this issue may be lacking, especially if code coverage numbers present a seemingly positive picture. However, focusing solely on code coverage provides a narrow perspective on the overall health of your test code base.\nAdditionally, these types of test suites fall short in narrating the essence of the application. Instead of conveying the domain, they tend to focus on technical implementation details. Similar to the concept of screaming architecture, tests should vividly scream what the application is about.2\nThe fragility and lack of documentation in tests can be attributed to an excessive emphasis on testing code in isolation. However, it prompts the question: what else should be tested if not the code we just wrote or want to write?\nA pinnacle of brittle tests focused on a technical implementation detail #Admittedly, a very simplistic example, yet I have already encountered tests that look almost exactly like this:\nclass PersonService { public void createPerson(Person person) { personRepository.save(person); } } var personRepository = mock(PersonRepository.class); var personService = new PersonService(personRepository); var person = PersonMother.male(); personService.createPerson(person); verify(personRepository).save(person); The Test Trigger # The trigger for a test is not a class nor a public method Ôºç Ian Cooper Ôºç TDD where did it all go wrong3\nFor an extended period, adding a new class or method was exactly what was driving my tests. Ironically, it was this idea on testing that made TDD comprehensible for me.\nThis commitment found additional reinforcement through the abundance of straightforward examples and tutorials available on writing tests and TDD, all consistently emphasizing explicit code testing.\nI believe that one should not test code explicitly, most of the time. So then naturally, the question arises, what should be tested explicitly if not code?\nBehavior First #Today I no longer let the creation of a method or class drive my tests. Instead, I focus on a fundamental question: why do I write code? I write code because there is always a requirement for a system to behave in a certain way. And that I try to capture in my tests.\nThis perspective should guide testing most of the time. Tests should stem from the requirements expected to be implemented, how the system should behave and not the methods and classes implementing those requirements.\nExplicitly Test Behavior To Implicitly Test The Code Covering That Behavior\nBy explicitly testing the expected behavior of your application, you will implicitly test almost all of your code. Any portions left untested by this method are likely unrelated to expected behaviors, relate to exceptional cases, such as checked exceptions, or configuration classes. As a consequence, your code coverage should be naturally high.\nI emphasized the significance of letting behavior guide your testing in the majority of cases. However, are there instances when this may not be the optimal approach? This question will be answered in the upcoming third installment of my Test First Series, where we go back in time to take a look at the classical Testing Pyramid.\nWikipedia (2023) https://en.wikipedia.org/w/index.php?title=Unit_testing\u0026oldid=1186674931\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nScreaming Architecture (2021) https://blog.cleancoder.com/uncle-bob/2011/09/30/Screaming-Architecture.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTDD where did it all go wrong (2017) https://youtu.be/EZ05e7EMOLM?si=2M-K1F0O53EYChU0\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"27 December 2023","permalink":"/posts/unit-test-ambiguity/","section":"Jonas on Software","summary":"\u003cp\u003eOn the Misconceptions Surrounding the Unit in Unit Testing\u003c/p\u003e","title":"\u003cspan style=\"color: #606a79; font-size: 90%;\"\u003eTest First Ôºç Part 2\u003c/span\u003e\u003cbr/\u003e The Unit Test Ambiguity"},{"content":" üé§ #","date":null,"permalink":"/talks/","section":"My Talks","summary":" üé§ #","title":"My Talks"},{"content":"Discover how the Object Mother concept empowers developers to effortlessly generate intricate test objects, enhancing code readability, maintainability, and overall testing efficiency.\nThe creational problem #A good structured test exists out of three parts commonly known as: Given When Then or Arrange Act Assert.\nWithin the Given part you declare a set of objects that will drive your test. Initially the creational logic is simple, as the objects may have fewer fields or lack coherence. However, inevitably over time, the set of objects grows as their intricacy, they become more complex and time-consuming to construct.\nVarious solutions exist to address those issues, such as Test Data Factories, Data Fakers, Test Data Generators or Fixture Builders etc .. In the end they all share a common goal: simplifying object creation while ensuring reusability. Martin Fowler has even coined a term for this concept, known as Object Mother.\nLet\u0026rsquo;s delve deeper into the problem by examining a concrete example. While this example may not be overly complex or entirely realistic, the purpose of this article is to work with practical scenarios without getting bogged down in the intricacies of object creation.\nAddress billingAddress = new Address.Builder() .streetAddress(\u0026#34;123 Main St\u0026#34;) .city(\u0026#34;Anytown\u0026#34;) .state(\u0026#34;CA\u0026#34;) .zipCode(\u0026#34;12345\u0026#34;) .country(Country.US) .build(); Address shippingAddress = new Address.Builder() .streetAddress(\u0026#34;456 Oak Ave\u0026#34;) .city(\u0026#34;Othertown\u0026#34;) .state(\u0026#34;CA\u0026#34;) .zipCode(\u0026#34;67890\u0026#34;) .country(Country.US) .build(); List\u0026lt;InvoiceItem\u0026gt; items = new ArrayList\u0026lt;\u0026gt;(); items.add(new InvoiceItem(\u0026#34;Product A\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21))); items.add(new InvoiceItem(\u0026#34;Product B\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21))); Customer customer = new Customer.Builder() .name(\u0026#34;John Doe\u0026#34;) .email(\u0026#34;john.doe@example.com\u0026#34;) .phoneNumber(\u0026#34;555-123-4567\u0026#34;) .build(); Invoice invoice = new Invoice( new InvoiceNumber(\u0026#34;001\u0026#34;), customer, billingAddressm, shippingAddress, LocalDate.now(), items); Amount amount = invoice.getVatAmount(); assertThat(amount).isEqualTo(Amount.EUR(42)) In the case of the aforementioned test, an Invoice object is needed, which, in turn, depends on several other objects. However, it is noteworthy that, for this specific test, only the invoice items hold significance. They play a vital role in asserting and calculating the VAT amount, all the other objects and fields just clutter the readability of the test.\nTest Data - Factory, Generator, Builder, Fixtures \u0026hellip; #There are numerous patterns available to create the required objects for your tests. A very common approach to simplify the creational logic while at the same time having some kind of of code reuse in place is to create static factory methods returning the required objects.\nInvoiceTestDataFactory.invoice(); While this approach may initially appear to solve the creational issue, it tends to scale poorly As Martin Fowler highlights:\nObject Mothers do have their faults. In particular there\u0026rsquo;s a heavy coupling in that many tests will depend on the exact data in the mothers.\nI\u0026rsquo;ve observed several solutions to address this issue, including;\ncreating specific static factory methods adding parameters to differentiate the creational logic. InvoiceTestDataFactory.invoiceWithoutShippingAddress(); InvoiceTestDataFactory.invoiceWithoutBillingAddressAndThreeItems(); InvoiceTestDataFactory.invoice(new InvoiceNumber(\u0026#34;001\u0026#34;), \u0026#34;john@doe,com\u0026#34;); InvoiceTestDataFactory.invoice( new InvoiceItem(\u0026#34;Product A\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21)), new InvoiceItem(\u0026#34;Product B\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21))); While these solutions may initially appear to solve the coupling issue, they often result in tight coupling between specific factory methods and the requirements of individual tests, limiting their reusability.\nOne introduces different factory methods or several sets of parameters because there are tests that require different permutations of the same objects under test.\nImagine you have an object with 5 primitive fields and 5 custom-typed fields. The question arises: how many permutations of factory methods or parameter sets would be required to cover all your test cases?\nIntroducing static factory methods or parameters might make the code challenging to maintain and may not facilitate effective communication within the Given part of your tests. Ultimately, pursuing this path leads to test data factories that are difficult to maintain and confusing to use.\nSo, how can we simplify the technical creational logic while simultaneously highlighting its essential aspects?\nEmphasize what matters and hide the irrelevant parts #By combining the Object Mother concept with pre-filled builders it becomes possible to hide away all unnecessary complexity while at the same time emphasizing what matters for your test-case.\nLet\u0026rsquo;s put this into practice using the previous example:\nInvoice invoice = InvoiceMother.invoice() .withInvoiceItems( new InvoiceItem(\u0026#34;Product A\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21)), new InvoiceItem(\u0026#34;Product B\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21))) .build(); Amount amount = invoice.getVatAmount(); assertThat(amount).isEqualTo(Amount.EUR(42)) üëâÔ∏è It\u0026rsquo;s important to stress the prefilled nature of a mother. Calling InvoiceMother.invoice().build() will return a fully fledged Invoice were all fields are filled in containing sensible default values.\nBy utilizing the approach mentioned above, the unnecessary clutter is eliminated, allowing the focus to be solely on what is essential for the test. In this particular case, it becomes evident that having two invoice items priced at EUR 100 each, with a 21% tax applied to each item, results in EUR 42 of taxes\nWe are still using some kind of static factory method, yet it does not immediately return our Invoice rather it returns a builder that allows you to override those defaults that matter for your specific test.\nI like to make the builder part of the Mother class as to reduce the chance to confuse it with production code InvoiceBuilders.\npublic class InvoiceMother { private InvoiceMother() { } public static Builder invoice() { return new Builder(); } public static class Builder { InvoiceNumber invoiceNumber = new InvoiceNumber(\u0026#34;001\u0026#34;); Customer customer = CustomerMother.customer().build(); Address billingAddress = AddressMother.address().build(); Address shippingAddress = AddressMother.address().build(); LocalDate creationDate = LocalDate.now(); List\u0026lt;InvoiceItem\u0026gt; items = List.of(InvoiceItemMother.item().build()); public Builder withItems(List\u0026lt;InvoiceItem\u0026gt; items) { this.items = items; return this; } // other setters are left out for brevity public Invoice build() { return new Invoice( invoiceNumber, customer, billingAddressm, shippingAddress, creationDate, items); } } } It\u0026rsquo;s important to note that the concept discussed here is not about the suffix \u0026lsquo;Mother.\u0026rsquo; If you find the suffix unfavorable, feel free to use any other suffix that better suits your needs, such as InvoiceTestDataFactory, InvoiceFixture, InvoiceTestData, and so on.\nWhat is important:\nLet your factory methods return Builders not the object under creation. Use a pre-filled Builder Limit your static factory methods to the absolute minimum. Rather override a field using the Builder than to introduce a new static factory method. What can flex:\nLet the defaults for custom complex objects depend on other Mothers The Mother suffix Making the Builder part of your Mother class But what if your test requires a specific field in one of the nested custom objects to be in a particular state? For instance, you may need the shipping address\u0026rsquo;s country to be set as \u0026lsquo;US,\u0026rsquo; while the other field values are irrelevant for your test. With the current setup, you would have to pass in another mother object and build it fully changing only that field that matter for your test.\nInvoiceMother.invoice() .withShippingAddress(AddressMother.addres() .withCountry(Country.US) .build()) .build(); Although this approach works, we can further improve it by utilizing a java.util.function.Consumer with the AddressMother.Builder:\nInvoiceMother.invoice() .withShippingAddress(b -\u0026gt; b.withCountry(Country.US)) .build(); In this case, the builder method would look like this:\npublic Builder withShippingAddress(Consumer\u0026lt;AddressMother.Builder\u0026gt; addressConsumer) { Address.Builder builder = AddressMother.address(); addressConsumer.accept(builder) this.shippingAddress = builder.build(); return this; } These enhancements aim to improve the readability and clarity of the code example while retaining the original meaning and intent.\nTakeaways #In conclusion, the Object Mother concept offers developers a powerful approach to effortlessly generate intricate test objects. By combining the concept with pre-filled builders, developers can effectively simplify the technical creational logic while emphasizing the essential aspects of their test cases.\nBy embracing the Object Mother concept and its principles, developers can achieve enhanced code readability, maintainability, and overall testing efficiency in their software projects. This becomes particularly crucial in complex projects, as tests serve not only to verify code correctness and guide design but also to serve as documentation and prevention of regression. When regression does occur, it is vital for both your future self and colleagues to clearly understand what is being tested.\n","date":null,"permalink":"/talks/your-tests-also-need-some-architecting/","section":"My Talks","summary":"\u003cp\u003eDiscover how the Object Mother concept empowers developers to effortlessly generate intricate test objects,\nenhancing code readability, maintainability, and overall testing efficiency.\u003c/p\u003e","title":"Your Tests Also Need Some Architecting"},{"content":"On the religious nature of TDD\nToday I practice a form of Test-Driven Development (TDD) whenever and wherever possible. However, this wasn\u0026rsquo;t always the case. At the beginning of my career, I was oblivious of it. To be honest, I wasn\u0026rsquo;t even focussed on writing tests; I was already content if the production code worked, and only then I would write a test.\nAs much as TDD practitioners would like, the adoption of the methodology, introduced by Kent Beck nearly 20 years ago, remains relatively low1. Conversely, an intriguing paradox emerges when we look beyond the mainstream landscape. TDD remains very much alive, championed by a large group of developers who diligently preach its virtues on social media channels and conferences.\nIn this article series, my goal is to offer a fresh perspective on TDD that goes beyond its common glorification served with oversimplified examples and rigid doctrine. I will provide practical insights to make TDD more recognizable and applicable to the complex challenges developers encounter today.\nNo TDD Never Implied no Tests #Compared to its adoption rate, it is prodigious to see TDD listed in many developer vacancies. Nevertheless, despite my experience spanning more than a decade in diverse teams, companies and projects, I\u0026rsquo;ve rarely encountered developers who wholeheartedly adopted TDD.\nTDD is like a rare bird in the wild, seldom seen but fascinating when it does appear.\nNot applying TDD never implied the absence of tests altogether. In fact, every project I\u0026rsquo;ve worked on has maintained a fair share of tests. Likewise, a significant number of developers with whom I\u0026rsquo;ve collaborated regarded a robust test suite as a cornerstone for the success of their projects. However, what I found to be a rarity was the practice of writing tests first, using these tests to guide the design and engaging in the classic red-green-refactor cycle.\nIn these environments, testing was perceived as a safety net rather than a compass for design. Developers wrote tests after the code was implemented, and the purpose of these tests was primarily to confirm that the code worked as intended and to warn them of regression later on.\nA Valuable Skill or Dogmatic Doctrine? #TDD undeniably played a significant role in putting testing on the map. It had a huge impact on how we develop software today and tomorrow. Nevertheless, it\u0026rsquo;s high time to confront the reality of the dogmatic perception TDD has acquired and cast a more illuminating spotlight on it.\nWhile TDD stands as a valuable methodology for ensuring software quality, I do not blindly want to follow its stringent approach. While its rules2 can helpful, they sometimes inadvertently constrain our approach to problem-solving:\nNot writing production code unless a failing test exists. Not writing more of a test than is necessary to fail. Not writing more production code than is needed to pass the one failing test. TDD is a skill that takes practice and experience to really benefit from it. It cannot be rigorously applied everywhere; experience will teach you this\nMisapplication or overzealous adherence to TDD principles can lead to exactly the opposite of what it might try to achieve.\nIn the world of software development, having a diverse skill set is essential. Therefore, I see TDD as one of the many skills that make up a developer\u0026rsquo;s arsenal, each contributing towards becoming a well-rounded and proficient software engineer.\nEmphasizing the Destination Over the Journey #In practice, I\u0026rsquo;ve learned that the presence of tests is more important than the specific details of how they are written. Whether tests are written using the TDD methodology or not, what truly matters is their role in ensuring the software\u0026rsquo;s correctness, guarding against regressions, serving as documentation and all together allow our software to evolve at a steady pace. While TDD may provide a structured approach, the ultimate goal is maintainable, reliable and well-tested software.\nI firmly advocate attempting to write your tests first, as it\u0026rsquo;s a valuable approach that doesn\u0026rsquo;t necessarily entail the strict adherence to the rules prescribed by traditional TDD.\nExploring the advantages of writing tests first will be our focus in the upcoming sections. However, before looking into that, the next episode will address The Unit Test Ambiguity, as it often hinders discussions about TDD.\nDiffblue. (2020). \u0026ldquo;DevOps and Testing Report.\u0026rdquo; Retrieved from https://www.diffblue.com/DevOps/research_papers/2020-devops-and-testing-report/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTheThreeRulesOfTdd. (2023). http://butunclebob.com/ArticleS.UncleBob.TheThreeRulesOfTdd\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"14 December 2023","permalink":"/posts/tdd-is-not-a-religion/","section":"Jonas on Software","summary":"\u003cp\u003eOn the religious nature of TDD\u003c/p\u003e","title":"\u003cspan style=\"color: #606a79; font-size: 90%;\"\u003eTest First Ôºç Part 1\u003c/span\u003e\u003cbr/\u003eTDD is Not a Religion"},{"content":"Tests must be encapsulated within methods that demand a name, and as with all aspects of programming, naming often proves to be the most challenging task.\nIn navigating the software landscape, I\u0026rsquo;ve encountered varied approaches to naming test methods. Some teams grant developers the freedom to name tests as they see fit. However, this often leads to a mix of clear, cryptic, misleading, or ambiguous test method names.\nConversely, certain teams enforce test method naming conventions to address these issues. Nevertheless, conventions can feel rigid, clumsy, and unfitting, sometimes resulting in problems similar to having no convention at all.\nThis article embarks on a journey to devise a practical strategy for defining test method names and their structure, all rooted in their inherent value. So, what truly defines the value of a test method name?\nExecutable pieces of documentation #Tests offer an invaluable yet often underestimated asset: their inherent documentation capabilities. As you write tests, you define the boundaries of your business logic or explore the capabilities of your infrastructural code, often without recognizing that you\u0026rsquo;re undertaking an additional vital task ‚Äî documenting the capabilities of your system.\nThe documentation value tests have goes beyond the static nature of traditional documentation found in sources like company wikis. Tests are living pieces of documentation, continuously evolving due to their executable nature. No feature or requirements should be left untested, hence it is documented. And when a test fails, often signalling regression or a change in the required behavior, you are prompted to correct it, ensuring both the accuracy of your system and the correctness of your documentation.\nThe Anatomy of a Superb Name #Conventional wisdom often stipulates that test method names should be concise and comprehensible, yet these directives occasionally lack the depth required to holistically define a well-documented test method name. Here are a few recommendations that I endorse:\nTranscending Standard Java Conventions #Although underscores in method names seldom grace production Java code, I propose that they\u0026rsquo;re an exception in the realm of test code. Test code operates under different rules and priorities, with clarity taking the utmost importance. Since test method names can occasionally become lengthy and words might feel crammed together, incorporating the option to use underscores provides a breathing space that contributes to more readable and comprehensible test names. Additionally, an underscore serves as a perfect separator, creating distinct and clear sections within the method name.\nThis also applies to moving beyond conventional Java method casing rules. Later you\u0026rsquo;ll find some unconventional usages of casing for the sake of readability.\nUbiquitous language #The ubiquitous language, gathered from business lingo and seamlessly integrated into your production code, should seamlessly extend to your test code, including method names.\nMove away from describing: What is being tested #If the essence of a test method name resides in its documentation value, then it\u0026rsquo;s logical to encapsulate the tested behavior within that name. Yet, countless tests merely encapsulate what\u0026rsquo;s being tested, neglecting to describe the behavior. This seemingly subtle distinction wields remarkable power.\nüí°Ask yourself, would the name be clear for a non-technical individual?\nüëé Examples of subpar test names that solely detail what\u0026rsquo;s being tested:\nvoid expireInvoiceTest() { void shouldStartReportJob() { void addPineappleToppingToPizzaTest() { void testCalculateIllegalVATRate() { Glossing over these test names leaves you guessing about the governing rules and expected behavior.\nWhat triggers an invoice\u0026rsquo;s expiration and what follows? What initiates the job and its subsequent outcomes? Is topping a pizza with pineapples allowed? What makes a VAT rate illegal? Avoid giving Examples #When writing a test, even when we are considering the behavior, we often transition from a general definition to a more concrete version. This is perfectly normal, as the test will implement the behavior using actual data or values. However, these example values should not imply their presence in our test method names\nüí°Exclude exemplar data from test method names\nüëé Examples of subpar test names that give examples of describing behavior:\nvoid shouldConsider_abc_asATooShortPassword() void testExpireInvoiceOnAugust15th() { void testReportJobStartsAt8AM() { void testCalculateMinus10PercentVatRate() { It does not describe the general rule which makes a password too short A specific date limits the understanding of the tested behavior to this exact date, lacking generality. Focuses on a particular time, limiting the overal comprehension of when the job should start. Mentions a precise VAT rate, which might not be clear in conveying the overall behavior. The issue with test naming conventions #The value in test method naming conventions often only remains confined to providing structural guidance. These conventions are indeed useful tools, ensuring codebase coherence and aiding new developers in quickly adapting to a consistent naming strategy.\nüí°Ô∏èWithout a primary focus on describing the behavior, conventions can sometimes fall short.\nMost conventions allow you to document the behavioral aspects of your codebase, irrespective of the structure they impose. As we\u0026rsquo;ve explored, a truly effective test method name should encapsulate the behavior, requirement, or feature being tested, though achieving this is often easier said than done.\nDeconstructing Common Conventions #For the remainder of this article, we\u0026rsquo;ll explore commonly found conventions. All examples will be written based on the following fictional requirement:\nüìù An outstanding invoice should incur an automatic 10% fee 30 days after its publication date.\nConvention: must start with should #One commonly encountered convention insists on using a should prefix. While this might naturally spotlight the outcome or the aspect under test, it somewhat sidelines the behavior.\nüëé Lacks complete behavior description:\nvoid shouldAutomaticallyIncur10PercentFee() { üëé Drifts from the ubiquitous language by using:\nadd instead of incur costs instead of fee unpaid instead of outstanding creation instead of publication void shouldAutomaticallAdd10PercentExtraCostsToAnUnpaidInvoice30DaysAfterCreationDate() { üëç Offers a more behavior-centric approach:\nvoid shouldAutomaticallIncur10PercentFeeToAnOutstandingInvoice30DaysAfterPublicationDate() { üëç Emphasizes clarity by sectioning with underscores:\nvoid shouldAutomaticallIncur10PercentFee_ToAnOutstandingInvoice_30DaysAfterPublicationDate() { Convention: Given_state_When_action_Then_outcome #The Given When Then paradigm offers a clear and structured way to capture all aspects of a well-defined behavior. It is well-recognized and used across various domains, making it familiar to developers and non-technical stakeholders alike. However, it\u0026rsquo;s important to note that this convention can become verbose due to the repeated use of Given, When, Then. This structure might lead to lengthy test method names, which could potentially impact readability and maintainability.\nüëç\nvoid Given_OustandingInvoice_When_30DaysAfterPublicationDate_Then_ShouldIncur10PercentFee() { Convention: Givenstate_Whenaction_Thenoutcome #Applying the same convention with a touch of brevity. However, the decision to include underscores ultimately hinges on individual taste and preference.\nüëç\nvoid GivenOustandingInvoice_When30DaysAfterPublicationDate_ThenShouldIncur10PercentFee() { Structural layout #Frequently when testing a requirement, you will need several tests to fully cover it. In this process, these tests can share similar components or structures, resulting in unnecessary redundancy in the test method name. To mitigate the lengthening of test method names, an interesting approach is to abstract these repetitions into distinct code segments. With the advent of JUnit 5, achieving this is feasible through the use of the @Nested annotation, allowing you to segregate the repetitions into separate classes.\nclass InvoiceTest { @Nested class GivenAnOustandingInvoice { @Test void whenPaymentExceeds30DaysLimit_Then_Incur10PercentFee() { @Test void whenWithin30DaysLimit_Then_NoFreeIsIncurred() { } class InvoiceTest { @Nested class ShouldIncur10PercentFee { @Test void whenPaymentExceeds30DaysLimit() { @Test void whenPaymentIsDoneByCreditCard() { However, this approach challenges common conventions, as most conventions primarily focus on method names.\nThrough my own experiences, I\u0026rsquo;ve explored various strategies and reached a definitive realization: while conventions offer structure, they might not inherently capture the intended focus on the behavior under test. It\u0026rsquo;s also worth considering expanding conventions beyond solely method naming and allowing them to be employed within nested classes, providing a holistic approach to enhancing test clarity.\nNo convention will be perfect, but it\u0026rsquo;s important to select one from the beginning and stick with it.\nüí°When selecting a convention, it is essential to recognize that the ultimate objective of a test name is to succinctly encapsulate the intended behavior.\nUpon completing a test, I\u0026rsquo;ve found it beneficial to revisit the test method itself and contemplate the following question:\nüí° If I were to revisit this test within a year or if a new colleague were to read it, would the name effectively convey the behavior without needing a deep dive into the implementation details?\n","date":"27 August 2023","permalink":"/posts/subtle-art-of-java-test-method-naming/","section":"Jonas on Software","summary":"\u003cp\u003eTests must be encapsulated within methods that demand a name, and as with all aspects of programming, naming often proves to be the most challenging task.\u003c/p\u003e","title":"The subtle Art of Java Test Method Naming"},{"content":"Explore strategies for reliable testing of time-dependent code, including techniques to mitigate flakiness in tests and enable precise time manipulation within your test suites.\nBy default, Java relies on the system clock to determine the current date and time. While in most cases this approach works fine when our system clock remains unchanged, it can quickly turn into a nightmare upon a simple faulty configuration change outside of your control.\nI have first-hand witnessed the consequences of an innocent OS upgrade silently altering the default time zone of a system. The impact was nothing short of disastrous, as all timestamps generated and stored by the application were suddenly off by a couple of hours. This post delves into the root cause of the issue, and as we will see, it presents a simple solution that at the same time enables us to write more robust tests and gain better control over the time-related aspects of our Java applications.\nThe time is now #The culprit of having our code depend on the system clock is the use of static java.time...now() methods such as:\nLocalDate.now() LocalDateTime.now() ZonedDateTime.now() OffsetDateTime.now() Instant.now() Examining the implementation of the ZonedDateTime.now() method in the JDK, we can see it delegates to another now method that takes a java.time.Clock instance as a parameter.\npublic final class ZonedDateTime implements Temporal, ChronoZonedDateTime\u0026lt;LocalDate\u0026gt;, Serializable { public static LocalTime now() { return now(Clock.systemDefaultZone()); } public static ZonedDateTime now(Clock clock) { Objects.requireNonNull(clock, \u0026#34;clock\u0026#34;); final Instant now = clock.instant(); // called once return ofInstant(now, clock.getZone()); } Within java.time.clock we can find a solution for ensuring our time related code is independent of the system\u0026rsquo;s time zone, while also facilitating easier testing. To further clarify this point, let\u0026rsquo;s refer to an excerpt from its documentation:\nUse of a Clock is optional. All key date-time classes also have a now() factory method that uses the system clock in the default time zone. The primary purpose of this abstraction is to allow alternate clocks to be plugged in as and when required. Applications use an object to obtain the current time rather than a static method. This can simplify testing.\nJava documentation\nThink of java.time.Clock as a physical wall clock that can be easily replaced with another clock within a different time zone. By passing along a java.time.Clock in all the java.time...now() methods, we decouple date-time generation from the system\u0026rsquo;s clock and simultaneously make it easier to test. As also stated in the documentation of the ZonedDateTime.now(Clock clock) method:\nUsing this method allows the use of an alternate clock for testing. The alternate clock may be introduced using dependency injection.\nJava documentation\nControlling the correct time zone #Passing a clock bound to a specific time zone frees us from relying solely on the system\u0026rsquo;s clock for date-time generation.\nZonedDateTime.now(Clock.system(ZoneId.of(\u0026#34;Europe/Brussels\u0026#34;))) By introducing a clock dependency, our production code becomes an area where accessing java.time.Clock is necessary. The same requirement extends to our tests, offering us significant benefits. In the next section, we will focus on the tests first and then proceed to examine our production code.\nFixating the clock #Having fine-grained control over date-time generation in our tests is indispensable for avoiding flaky tests. Java helps by allowing us to fixate the clock on a certain date-time within a specific time zone:\nClock.fixed(Instant.parse(\u0026#34;1985-02-25T23:00:00.00Z\u0026#34;), ZoneId.of(\u0026#34;Europe/Brussels\u0026#34;)); Let\u0026rsquo;s take the following piece of production code we want to test:\npublic class Order { private Status status; private LocalDateTime processDateTime; public Order markAsProcessed() { this.processDateTime = LocalDateTime.now(); this.status = PROCESSED; } } By adding a java.time.Clock as a dependency this becomes easily and accurately testsable:\npublic Order markAsProcessed(Clock clock) { this.processDateTime = LocalDateTime.now(clock); Which would result in the following test:\n// given var order = OrderMother.newOrder(); // when var clock = Clock.fixed(Instant.parse(\u0026#34;1985-02-25T23:00:00.00Z\u0026#34;), ZoneId.of(\u0026#34;Europe/Brussels\u0026#34;); order.markAsProcessed(clock); // then assertThat(order.processDateTime()) .isEqualTo(LocalDateTime.parse(\u0026#34;1985-02-26T00:00:00\u0026#34;)); Notice how in the assertion the day has moved on by one hour and one day, because the date-time is generated in a +1 time zone.\nAlternative solutions #Truncating time for more precision #There are alternative solutions available for testing date-time generation if you prefer not to rely on java.time.Clock. However, it\u0026rsquo;s important to note that relying solely on the system\u0026rsquo;s default clock carries its own risks.\nThe problem with asserting the generated date-time is that even a small amount of time between generating the date-time and asserting it can lead to faulty assertions. Consequently, this test example without the clock will likely be unreliable:\n// given var order = OrderMother.newOrder(); // when order.markAsProcessed(); // then assertThat(order.processDateTime()) .isEqualTo(LocalDateTime.now()); This test is prone to flakiness and will probably fail consistently due to the time that elapses between the markAsProcessed method\u0026rsquo;s LocalDateTime.now() call and the actual assertion. To mitigate this, you can truncate the generated date-time to seconds or milliseconds and perform the same truncation in the assertion. While this approach reduces flakiness, it doesn\u0026rsquo;t guarantee 100% accuracy. But in most cases that trade-off is acceptable. Here\u0026rsquo;s an example of truncating to seconds in your production code:\nInstant.now().truncatedTo(ChronoUnit.SECONDS) And this can be tested like so:\n// given var order = OrderMother.newOrder(); // when order.markAsProcessed(); // then assertThat(order.processDateTime()) .isEqualTo(LocalDateTime.now().truncatedTo(ChronoUnit.SECONDS)); Wondering what this OrderMother is, check out my previous article on mothers\nAssert that the generated time is close enough to now #A second alternative is to utilize AssertJ\u0026rsquo;s .closeTo assertion methods, which provides a convenient way to assert values within a specified range. Here are a couple of examples to illustrate this:\nvar localDateTime = LocalDateTime.now(Clock.systemUTC()); assertThat(localDateTime) .isCloseToUtcNow(within(1, ChronoUnit.SECONDS)); var instant = Instant.parse(\u0026#34;2000-01-01T00:00:00.00Z\u0026#34;) assertThat(instant) .isCloseTo(\u0026#34;1999-12-31T23:59:59.99Z\u0026#34;, within(10, ChronoUnit.MILLIS)) Clock as a spring bean #Going forward with the clock. Whenever we require access to the current date-time, it is necessary to have access to the clock. However, passing the clock object throughout our code can become cumbersome. Fortunately, most modern applications make use of an IoC (Inversion of Control) Container, which alleviates this burden. As a result, we will expose the Clock as an object eligible for inversion of control or, in Spring terminology, convert it into a bean.\n@Configuration class ClockConfiguration { @Bean Clock clock(@Value(\u0026#34;${app.time.zone-id}\u0026#34;) String zoneId){ return Clock.system(ZoneId.of(zoneId)); } } Depending on our needs, we have the option to either hard-code the active timezone or, as demonstrated in the example above, make it configurable. In either case, this approach allows us to conveniently inject the clock whenever necessary, as illustrated in the example below.\n@Service public class OrderService { private final Clock clock; private final OrderRepository orderRepository; public OrderService(OrderRepository orderRepository, Clock clock) { this.clock = clock; this.orderRepository = orderRepository; } public void processOrder(OrderId orderId) { var order = orderRepository.findById(orderId); order.markAsProcessed(clock); // etc .. } } Particularly within testing scenarios, having a clock eligible for inversion of control becomes critical. As it empowers us to precisely control and manipulate time-related behavior in our tests. Just like in our unit tests, let\u0026rsquo;s start by exposing a fixated clock.\n@Configuration public class TestClockConfiguration { @Bean @Primary Clock fixedClock() { return Clock.fixed(Instant.parse(\u0026#34;1985-02-25T23:00:00.00Z\u0026#34;), ZoneId.of(\u0026#34;Europe/Brussels\u0026#34;); } } To ensure consistent time behavior across all tests within a Spring context, we can include the above configuration in our test package. This will, due to the use of @Primary override the clock defined in our production code with a fixed clock. Now we can assert the order to be marked as processed at the fixed date-time.\nWhat if we require precise control over the clock at a per-test level within a single Spring context, without the need to create a new context for each case where a different clock is desired? Or maybe we want to play with our current date-time and actually move time forward or maybe even rewind it? The next section will cover these use-cases.\nMutable clock #The default java.time.Clock implementation is immutable in the sense that you can not change it\u0026rsquo;s current date-time or timezone. By incorporating a mutable clock that can manipulate time or be set to a specific date-time within our tests, we can avoid the need for multiple Spring contexts.\npublic class MutableClock extends Clock { private Instant instant; private final ZoneId zone; public MutableClock(Instant instant, ZoneId zone) { this.instant = instant; this.zone = zone; } @Override public ZoneId getZone() { return zone; } @Override public Clock withZone(ZoneId zone) { return new MutableClock(instant, zone); } @Override public Instant instant() { return instant; } public void fastForward(TemporalAmount temporalAmount) { set(instant().plus(temporalAmount)); } public void rewind(TemporalAmount temporalAmount) { set(instant().minus(temporalAmount)); } public void set(Instant instant) { this.instant = instant; } public static MutableClock fixed(Instant instant, ZoneId zone) { return new MutableClock(instant, zone); } public static MutableClock fixed(OffsetDateTime offsetDateTime) { return fixed(offsetDateTime.toInstant(), offsetDateTime.getOffset()); } } Exposing the mutable clock:\n@Configuration public class TestClockConfiguration { @Bean @Primary Clock testClock(@Value(\u0026#34;${app.time.zone-id}\u0026#34;) String zoneId) { return new MutableClock(Instant.parse(\u0026#34;1985-02-25T23:00:00.00Z\u0026#34;), ZoneId.of(zoneId)); } } Now, let\u0026rsquo;s put this knowledge to good use by writing a test for the following piece of production code:\n@Component public class OrderProcessor { private final Clock clock; private final LocalTime startOfWorkingDay = LocalTime.of(8, 0); private final LocalTime endOfWorkingDay = LocalTime.of(22, 0); public OrderProcessor(Clock clock) { this.clock = clock; } public void processOrder(Order order) { if (isWithinWorkingHours()) { processNow(order); } else { processLater(order); } } public boolean isWithinWorkingHours() { LocalTime now = LocalTime.now(clock) return !now.isBefore(startOfWorkingDay) \u0026amp;\u0026amp; !time.isAfter(endOfWorkingDay); } } public class OrderProcessingFeatureTest { private final MutableClock mutableClock; public OrderProcessingFeatureTest(Clock clock) { this.mutableClock = (MutableClock)clock; } @Test void shouldProcessOrderWithinWorkingHours() { // given mutableClock.set(Instant.parse(\u0026#34;2023-02-25T13:00:00.00Z\u0026#34;)) // when var resultActions = mockMvc.perform(post(\u0026#34;/orders/ORD567890\u0026#34;) .contentType(MediaType.APPLICATION_JSON) .content(toJson(OrderMother.defaultOrder())); // then resultActions.andExpect(status().isOk()) .andExpect(jsonPath(\u0026#34;$.status\u0026#34;).value(\u0026#34;PROCESSED\u0026#34;)); } @Test void shouldProcessOrderLaterWhenReceivedOutsideOfWorkingHours() { // given mutableClock.set(Instant.parse(\u0026#34;2023-02-25T23:00:00.00Z\u0026#34;)) // when var resultActions = mockMvc.perform(post(\u0026#34;/orders/ORD4785669\u0026#34;) .contentType(MediaType.APPLICATION_JSON) .content(toJson(OrderMother.defaultOrder())); // then resultActions.andExpect(status().isOk()) .andExpect(jsonPath(\u0026#34;$.status\u0026#34;).value(\u0026#34;PROCESS_LATER\u0026#34;)); } } In conclusion, leveraging the java.time.Clock class and its capability to decouple date-time generation from the system clock empowers us to write more effective tests for time-dependent code. This approach not only grants us greater control over time-related aspects but also acts as a safeguard against issues arising from system clock changes, as I have personally encountered.\n","date":"9 July 2023","permalink":"/posts/how-to-effectively-test-time-dependent-code/","section":"Jonas on Software","summary":"\u003cp\u003eExplore strategies for reliable testing of time-dependent code, including techniques to mitigate flakiness in tests and enable precise time manipulation within your test suites.\u003c/p\u003e","title":"How to Effectively Test Time-Dependent Code: Unit and Spring-Based Strategies"},{"content":"Discover how the Object Mother concept empowers developers to effortlessly generate intricate test objects, enhancing code readability, maintainability, and overall testing efficiency.\nThe creational problem #A good structured test exists out of three parts commonly known as: Given When Then or Arrange Act Assert.\nWithin the Given part you declare a set of objects that will drive your test. Initially the creational logic is simple, as the objects may have fewer fields or lack coherence. However, inevitably over time, the set of objects grows as their intricacy, they become more complex and time-consuming to construct.\nVarious solutions exist to address those issues, such as Test Data Factories, Data Fakers, Test Data Generators or Fixture Builders etc .. In the end they all share a common goal: simplifying object creation while ensuring reusability. Martin Fowler has even coined a term for this concept, known as Object Mother.\nLet\u0026rsquo;s delve deeper into the problem by examining a concrete example. While this example may not be overly complex or entirely realistic, the purpose of this article is to work with practical scenarios without getting bogged down in the intricacies of object creation.\nAddress billingAddress = new Address.Builder() .streetAddress(\u0026#34;123 Main St\u0026#34;) .city(\u0026#34;Anytown\u0026#34;) .state(\u0026#34;CA\u0026#34;) .zipCode(\u0026#34;12345\u0026#34;) .country(Country.US) .build(); Address shippingAddress = new Address.Builder() .streetAddress(\u0026#34;456 Oak Ave\u0026#34;) .city(\u0026#34;Othertown\u0026#34;) .state(\u0026#34;CA\u0026#34;) .zipCode(\u0026#34;67890\u0026#34;) .country(Country.US) .build(); List\u0026lt;InvoiceItem\u0026gt; items = new ArrayList\u0026lt;\u0026gt;(); items.add(new InvoiceItem(\u0026#34;Product A\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21))); items.add(new InvoiceItem(\u0026#34;Product B\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21))); Customer customer = new Customer.Builder() .name(\u0026#34;John Doe\u0026#34;) .email(\u0026#34;john.doe@example.com\u0026#34;) .phoneNumber(\u0026#34;555-123-4567\u0026#34;) .build(); Invoice invoice = new Invoice( new InvoiceNumber(\u0026#34;001\u0026#34;), customer, billingAddressm, shippingAddress, LocalDate.now(), items); Amount amount = invoice.getVatAmount(); assertThat(amount).isEqualTo(Amount.EUR(42)) In the case of the aforementioned test, an Invoice object is needed, which, in turn, depends on several other objects. However, it is noteworthy that, for this specific test, only the invoice items hold significance. They play a vital role in asserting and calculating the VAT amount, all the other objects and fields just clutter the readability of the test.\nTest Data - Factory, Generator, Builder, Fixtures \u0026hellip; #There are numerous patterns available to create the required objects for your tests. A very common approach to simplify the creational logic while at the same time having some kind of of code reuse in place is to create static factory methods returning the required objects.\nInvoiceTestDataFactory.invoice(); While this approach may initially appear to solve the creational issue, it tends to scale poorly As Martin Fowler highlights:\nObject Mothers do have their faults. In particular there\u0026rsquo;s a heavy coupling in that many tests will depend on the exact data in the mothers.\nI\u0026rsquo;ve observed several solutions to address this issue, including;\ncreating specific static factory methods adding parameters to differentiate the creational logic. InvoiceTestDataFactory.invoiceWithoutShippingAddress(); InvoiceTestDataFactory.invoiceWithoutBillingAddressAndThreeItems(); InvoiceTestDataFactory.invoice(new InvoiceNumber(\u0026#34;001\u0026#34;), \u0026#34;john@doe,com\u0026#34;); InvoiceTestDataFactory.invoice( new InvoiceItem(\u0026#34;Product A\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21)), new InvoiceItem(\u0026#34;Product B\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21))); While these solutions may initially appear to solve the coupling issue, they often result in tight coupling between specific factory methods and the requirements of individual tests, limiting their reusability.\nOne introduces different factory methods or several sets of parameters because there are tests that require different permutations of the same objects under test.\nImagine you have an object with 5 primitive fields and 5 custom-typed fields. The question arises: how many permutations of factory methods or parameter sets would be required to cover all your test cases?\nIntroducing static factory methods or parameters might make the code challenging to maintain and may not facilitate effective communication within the Given part of your tests. Ultimately, pursuing this path leads to test data factories that are difficult to maintain and confusing to use.\nSo, how can we simplify the technical creational logic while simultaneously highlighting its essential aspects?\nEmphasize what matters and hide the irrelevant parts #By combining the Object Mother concept with pre-filled builders it becomes possible to hide away all unnecessary complexity while at the same time emphasizing what matters for your test-case.\nLet\u0026rsquo;s put this into practice using the previous example:\nInvoice invoice = InvoiceMother.invoice() .withInvoiceItems( new InvoiceItem(\u0026#34;Product A\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21)), new InvoiceItem(\u0026#34;Product B\u0026#34;, Amount.EUR(100.00), Tax.vatPercentage(21))) .build(); Amount amount = invoice.getVatAmount(); assertThat(amount).isEqualTo(Amount.EUR(42)) üëâÔ∏è It\u0026rsquo;s important to stress the prefilled nature of a mother. Calling InvoiceMother.invoice().build() will return a fully fledged Invoice were all fields are filled in containing sensible default values.\nBy utilizing the approach mentioned above, the unnecessary clutter is eliminated, allowing the focus to be solely on what is essential for the test. In this particular case, it becomes evident that having two invoice items priced at EUR 100 each, with a 21% tax applied to each item, results in EUR 42 of taxes\nWe are still using some kind of static factory method, yet it does not immediately return our Invoice rather it returns a builder that allows you to override those defaults that matter for your specific test.\nI like to make the builder part of the Mother class as to reduce the chance to confuse it with production code InvoiceBuilders.\npublic class InvoiceMother { private InvoiceMother() { } public static Builder invoice() { return new Builder(); } public static class Builder { InvoiceNumber invoiceNumber = new InvoiceNumber(\u0026#34;001\u0026#34;); Customer customer = CustomerMother.customer().build(); Address billingAddress = AddressMother.address().build(); Address shippingAddress = AddressMother.address().build(); LocalDate creationDate = LocalDate.now(); List\u0026lt;InvoiceItem\u0026gt; items = List.of(InvoiceItemMother.item().build()); public Builder withItems(List\u0026lt;InvoiceItem\u0026gt; items) { this.items = items; return this; } // other setters are left out for brevity public Invoice build() { return new Invoice( invoiceNumber, customer, billingAddressm, shippingAddress, creationDate, items); } } } It\u0026rsquo;s important to note that the concept discussed here is not about the suffix \u0026lsquo;Mother.\u0026rsquo; If you find the suffix unfavorable, feel free to use any other suffix that better suits your needs, such as InvoiceTestDataFactory, InvoiceFixture, InvoiceTestData, and so on.\nWhat is important:\nLet your factory methods return Builders not the object under creation. Use a pre-filled Builder Limit your static factory methods to the absolute minimum. Rather override a field using the Builder than to introduce a new static factory method. What can flex:\nLet the defaults for custom complex objects depend on other Mothers The Mother suffix Making the Builder part of your Mother class But what if your test requires a specific field in one of the nested custom objects to be in a particular state? For instance, you may need the shipping address\u0026rsquo;s country to be set as \u0026lsquo;US,\u0026rsquo; while the other field values are irrelevant for your test. With the current setup, you would have to pass in another mother object and build it fully changing only that field that matter for your test.\nInvoiceMother.invoice() .withShippingAddress(AddressMother.address() .withCountry(Country.US) .build()) .build(); Although this approach works, we can further improve it by utilizing a java.util.function.Consumer with the AddressMother.Builder:\nInvoiceMother.invoice() .withShippingAddress(b -\u0026gt; b.withCountry(Country.US)) .build(); In this case, the builder method would look like this:\npublic Builder withShippingAddress(Consumer\u0026lt;AddressMother.Builder\u0026gt; addressConsumer) { Address.Builder builder = AddressMother.address(); addressConsumer.accept(builder) this.shippingAddress = builder.build(); return this; } These enhancements aim to improve the readability and clarity of the code example while retaining the original meaning and intent.\nTakeaways #In conclusion, the Object Mother concept offers developers a powerful approach to effortlessly generate intricate test objects. By combining the concept with pre-filled builders, developers can effectively simplify the technical creational logic while emphasizing the essential aspects of their test cases.\nBy embracing the Object Mother concept and its principles, developers can achieve enhanced code readability, maintainability, and overall testing efficiency in their software projects. This becomes particularly crucial in complex projects, as tests serve not only to verify code correctness and guide design but also to serve as documentation and prevention of regression. When regression does occur, it is vital for both your future self and colleagues to clearly understand what is being tested.\n","date":"5 June 2023","permalink":"/posts/object-mother/","section":"Jonas on Software","summary":"\u003cp\u003eDiscover how the Object Mother concept empowers developers to effortlessly generate intricate test objects,\nenhancing code readability, maintainability, and overall testing efficiency.\u003c/p\u003e","title":"Mastering the Object Mother"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":" üìö Some noteworthy projects I\u0026rsquo;ve created along the way. Xjx #Java based XML serializing and deserializing (serdes) library.\nüè° homepage: https://github.com/jonas-grgt/xjx\nExample deserialization usage: #class Gpx { @Tag(path = \u0026#34;/gpx\u0026#34;, items = \u0026#34;wpt\u0026#34;) List\u0026lt;Wpt\u0026gt; wpts; } class Wpt { @Tag(path = \u0026#34;/gpx/wpt/name\u0026#34;) String name; } var gpx = new XjxSerdes().read(\u0026#34;\u0026#34;\u0026#34; \u0026lt;gpx version=\u0026#34;1.0\u0026#34; creator=\u0026#34;ExpertGPS 1.1 - https://www.topografix.com\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://www.topografix.com/GPX/1/0\u0026#34; xsi:schemaLocation=\u0026#34;http://www.topografix.com/GPX/1/0 http://www.topografix.com/GPX/1/0/gpx.xsd\u0026#34;\u0026gt; \u0026lt;time\u0026gt;2002-02-27T17:18:33Z\u0026lt;/time\u0026gt; \u0026lt;bounds minlat=\u0026#34;42.401051\u0026#34; minlon=\u0026#34;-71.126602\u0026#34; maxlat=\u0026#34;42.468655\u0026#34; maxlon=\u0026#34;-71.102973\u0026#34;/\u0026gt; \u0026lt;wpt lat=\u0026#34;42.438878\u0026#34; lon=\u0026#34;-71.119277\u0026#34;\u0026gt; \u0026lt;ele\u0026gt;44.586548\u0026lt;/ele\u0026gt; \u0026lt;time\u0026gt;2001-11-28T21:05:28Z\u0026lt;/time\u0026gt; \u0026lt;name\u0026gt;5066\u0026lt;/name\u0026gt; \u0026lt;desc\u0026gt;\u0026lt;![CDATA[5066]]\u0026gt;\u0026lt;/desc\u0026gt; \u0026lt;sym\u0026gt;Crossing\u0026lt;/sym\u0026gt; \u0026lt;type\u0026gt;\u0026lt;![CDATA[Crossing]]\u0026gt;\u0026lt;/type\u0026gt; \u0026lt;/wpt\u0026gt; \u0026lt;/gpx\u0026gt; \u0026#34;\u0026#34;\u0026#34;, Gpx.class); ","date":null,"permalink":"/my-open-code-overture/","section":"","summary":"üìö Some noteworthy projects I\u0026rsquo;ve created along the way.","title":"My Open Code Overture"},{"content":"","date":null,"permalink":"/tags/opensource/","section":"Tags","summary":"","title":"Opensource"},{"content":"","date":null,"permalink":"/tags/projects/","section":"Tags","summary":"","title":"Projects"}]